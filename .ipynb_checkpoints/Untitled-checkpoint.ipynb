{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calibrate Camera\n",
    "#prepare object points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "#Arrays to store object points and image points from all the images\n",
    "objpoints = [] #3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "#Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "#Step through the lsit and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #find corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    #If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        #Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (8,6), corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistort(img, objpoints, imgpoints):\n",
    "    '''\n",
    "    undistorts and image\n",
    "    input: image, list of objpoints, and list of imgpoints\n",
    "    output: undistorted image\n",
    "    '''\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #print(img_size)\n",
    "\n",
    "    #Do camera calibration give obj points and img points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    #visualize undistortion\n",
    "    #visualizeUndistort(img, dst)\n",
    "    #return undistorted image\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualizeUndistort(img, dst):\n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize = (20, 10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transform to birds eye view\n",
    "def perspectiveTransform(img):\n",
    "    '''\n",
    "    updates a photo to make it bird's eye view\n",
    "    input: Original image\n",
    "    output: Transformed image\n",
    "    '''\n",
    "    offset = 100\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    #find source and destination points\n",
    "    #####################################################\n",
    "    src = np.float32([]) # find points from my mask?\n",
    "    #####################################################\n",
    "    dst = np.float32([[offset, offset], [img_size[0] - offset, offset], [img_size[0] - offset, img_size[1] - offset], [offset, img_size[1] - offset]]) \n",
    "    #compute perspective transform, M\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    #warp image\n",
    "    warp = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sobel x plus S_gradient, put on mask\n",
    "def thresholding(img, sobel_t_min = 20, sobel_t_max = 100, s_t_min = 170, s_t_max = 255):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sobel_t_min) & (scaled_sobel <= sobel_t_max)] = 1\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = np.seros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_t_min) & (s_channel <= s_t_max)] = 1\n",
    "\n",
    "    #stack both to see the individual contributions. Green for Sobel, Blue for Saturation (HLS)\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "    #combine the two thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary ==1) | (sxbinary ==1)] =1\n",
    "\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training for lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating polyfit of left and right lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drawing line on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filling in area on image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
