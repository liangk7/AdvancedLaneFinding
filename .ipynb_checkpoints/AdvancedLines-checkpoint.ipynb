{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Import Statments\n",
    "##############################################\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Defining Frame Class\n",
    "##############################################\n",
    "class Frame():\n",
    "    #This class stores all of the different images in this program. Can be used later\n",
    "    def __init__(self):\n",
    "        self.original = None\n",
    "        self.undst = None\n",
    "        self.gray = None\n",
    "        self.warp = None\n",
    "        self.hls = None\n",
    "        self.h_channel = None\n",
    "        self.l_channel = None\n",
    "        self.s_channel = None\n",
    "        self.s_binary = None\n",
    "        self.sxbinary = None\n",
    "        self.sx_s_channel_binary = None\n",
    "        self.color_binary = None\n",
    "        self.combined_binary = None\n",
    "        self.both_lines = None\n",
    "        self.finalImage = None\n",
    "        self.mesh = None\n",
    "        self.scaled_sobel = None\n",
    "        self.border = None\n",
    "\n",
    "        self.M = None\n",
    "        self.Minv = None\n",
    "        self.objpoints = None\n",
    "        self.imgpoints = None\n",
    "\n",
    "        self.leftLine = Line()\n",
    "        self.rightLine = Line()\n",
    "\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Defining Line Class\n",
    "##############################################\n",
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Was the line detected in the last iteration?\n",
    "        ##done\n",
    "        self.detected = False\n",
    "        \n",
    "        #x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "\n",
    "        #polynomial coefficents with world scale averaged over the last n interations\n",
    "        self.best_world_fit = None\n",
    "\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []\n",
    "\n",
    "        #polynomial coefficients for most recent fits in world view\n",
    "        self.current_world_fit = []\n",
    "\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "\n",
    "\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype = 'float')\n",
    "        \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None\n",
    "\n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "    def isLineDetected(self):\n",
    "        return self.detected\n",
    "    \n",
    "    def updateLine(self, current_fit, current_fitx, world_fit, allx, ally):\n",
    "        #updates the lines and sets the detected flag to true if we've had success in the past 5 runs, otherwise it sets it to false\n",
    "\n",
    "        #Check if we're detected first, if not, just add the line\n",
    "        if self.detected:\n",
    "            #update diffs\n",
    "            self.diffs = self.current_fit[-1] - current_fit\n",
    "\n",
    "        #if the differences are too high, abort and set detected to false\n",
    "        if current_fit is not None:\n",
    "            if ((self.diffs[0] > 0.001) or (self.diffs[1] > 1) or (self.diffs[2] > 100)):\n",
    "                #If difference is too crazy, abort and call remove line function\n",
    "                self.removeLine()\n",
    "            else:\n",
    "                self.detected = True\n",
    "            \n",
    "                #update all x and all y\n",
    "                self.allx = allx\n",
    "                self.ally = ally\n",
    "\n",
    "                #update polynomial coefficients\n",
    "                self.current_fit.append(current_fit)\n",
    "                self.current_world_fit.append(world_fit)\n",
    "                self.recent_xfitted.append(current_fitx)\n",
    "                \n",
    "                if len(self.recent_xfitted) > 5:\n",
    "                    #pop the first one if we have over 5 recent fits. Over flow protection\n",
    "                    self.recent_xfitted.pop(0)\n",
    "                if len(self.current_world_fit) > 5:\n",
    "                    self.current_world_fit.pop(0)\n",
    "                if len(self.current_fit) > 5:\n",
    "                    self.current_fit.pop(0)\n",
    "                  \n",
    "                #average lines here and set bestx and best_fit values. Use these values for drawings\n",
    "                if len(self.recent_xfitted) > 0:\n",
    "                    self.bestx = np.average(self.recent_xfitted, axis = 0)\n",
    "                if len(self.current_fit) > 0 :\n",
    "                    self.best_fit = np.average(self.current_fit, axis = 0)\n",
    "                if len(self.current_world_fit) > 0:\n",
    "                    self.best_world_fit = np.average(self.current_world_fit, axis = 0)\n",
    "\n",
    "\n",
    "                #Find curvature\n",
    "                self.findRadius()\n",
    "        #Else, no line available, set flag to not detected\n",
    "        else:\n",
    "            self.removeLine()\n",
    "\n",
    "\n",
    "\n",
    "    def removeLine(self):\n",
    "        #remove oldest instance of recent_xfitted and current_fit so that when it's 0 we can do sliding window method again\n",
    "        if len(self.recent_xfitted) > 0:\n",
    "            self.recent_xfitted.pop(0)\n",
    "        if len(self.current_fit) > 0:\n",
    "            self.current_fit.pop(0)\n",
    "        if len(self.current_world_fit) > 0:\n",
    "            self.current_world_fit.pop(0)\n",
    "        if len(self.recent_xfitted) == 0 or len(self.current_fit) ==0:\n",
    "            #When we have nothing left, reset and go back to default values\n",
    "            self.detected = False\n",
    "            self.diffs = np.array([0,0,0], dtype = 'float')\n",
    "     \n",
    "    def findRadius(self, height = 720):\n",
    "        #Second argument is either 720 or image size\n",
    "        \n",
    "        #Conversions from pixel to real world\n",
    "        ploty = np.linspace(0, height -1, height)\n",
    "        y_eval = np.max(ploty)\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        \n",
    "        #fit_worldSpace = np.polyfit(ym_per_pix * self.ally, xm_per_pix * self.allx, 2)\n",
    "        fit_worldSpace = self.best_world_fit\n",
    "        curverad = ((1 + (2*fit_worldSpace[0] * y_eval * ym_per_pix+ fit_worldSpace[1])**2)**1.5)/ np.absolute(2*fit_worldSpace[0])\n",
    "        self.radius_of_curvature = curverad\n",
    "        print('curverad', curverad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Defining Helper Functions\n",
    "##############################################\n",
    "def undistort(Frame):\n",
    "    '''\n",
    "    undistorts and image\n",
    "    input: image, list of objpoints, and list of imgpoints\n",
    "    output: undistorted image\n",
    "    '''\n",
    "    img = Frame.original\n",
    "    objpoints = Frame.objpoints\n",
    "    imgpoints = Frame.imgpoints\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    #Do camera calibration give obj points and img points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    undst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    Frame.undst = undst\n",
    "\n",
    "def visualizeImage(name, img):\n",
    "    '''\n",
    "    Takes in a name and image, displays it on computer\n",
    "    '''\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "#Transform to birds eye view\n",
    "def perspectiveTransform(Frame):\n",
    "    '''\n",
    "    updates a photo to make it bird's eye view\n",
    "    input: Original image\n",
    "    output: Transformed image\n",
    "    '''\n",
    "    offset = 50\n",
    "    undst = np.copy(Frame.undst)\n",
    "    img_size = (undst.shape[1], undst.shape[0])\n",
    "\n",
    "    #Choose source and destination points\n",
    "    src = np.float32([[535, 465], [745,465], [95, 670], [1185, 670]])\n",
    "    dst = np.float32([[offset, offset], [img_size[0] - offset, offset], [offset, img_size[1] - offset], [img_size[0] - offset, img_size[1] - offset]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Frame.M = M\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    Frame.Minv = Minv\n",
    "    warp = cv2.warpPerspective(undst, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    Frame.warp = warp\n",
    "\n",
    "    #show src area on image\n",
    "    pts = np.array([[src[0][0],src[0][1]],[src[1][0],src[1][1]], [src[3][0],src[3][1]],[src[2][0],src[2][1]]], np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    Frame.border = cv2.polylines(undst,[pts], True, (0,255,255))\n",
    "\n",
    "#Sobel x plus S_gradient, put on mask\n",
    "def thresholding(Frame, sobel_t_min = 50, sobel_t_max = 255, s_t_min = 200, s_t_max = 255):\n",
    "    warp = Frame.warp\n",
    "    gray = cv2.cvtColor(warp, cv2.COLOR_BGR2GRAY)\n",
    "    Frame.gray = gray\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) \n",
    "    abs_sobelx = np.absolute(sobelx)   \n",
    "    scaled_sobel = 255*abs_sobelx/np.max(abs_sobelx)\n",
    "    Frame.scaled_sobel = scaled_sobel\n",
    "    \n",
    "    #Sobel binary\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sobel_t_min) & (scaled_sobel <= sobel_t_max)] = 1\n",
    "    \n",
    "    Frame.sxbinary = sxbinary\n",
    "    \n",
    "    hls = cv2.cvtColor(warp, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    Frame.hls = hls\n",
    "    Frame.h_channel = h_channel\n",
    "    Frame.l_channel = l_channel\n",
    "    Frame.s_channel = s_channel\n",
    "\n",
    "    #S binary\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_t_min) & (s_channel <= s_t_max)] = 1\n",
    "    Frame.s_binary = s_binary\n",
    "    \n",
    "    #Sobelx the S_channel\n",
    "    print('s_channel shape',s_channel.shape)\n",
    "    \n",
    "    sobel_x_s_channel = cv2.cvtColor(s_channel, -1,1,0)\n",
    "    abs_sobel_x_s_channel = np.absolute(sobel_x_s_channel)\n",
    "    scaled_sobel_s_channel = 255 * abs_sobel_x_s_channel/np.max(abs_sobel_x_s_channel)\n",
    "    #s_channel sobel binary\n",
    "    sx_s_channel_binary = np.zeros_like(scaled_sobel_s_channel)\n",
    "    sx_s_channel_binary[(scaled_sobel_s_channel >= sobel_t_min) & (scaled_sobel_s_channel <= sobel_t_max)] = 1\n",
    "    \n",
    "    Frame.sx_s_channel_binary = sx_s_channel_binary\n",
    "    \n",
    "    #stack both to see the individual contributions. Green for Sobel, Blue for Saturation (HLS)\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, sx_s_channel_binary)) * 255\n",
    "    Frame.color_binary = color_binary\n",
    "\n",
    "    #combine the two thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(sx_s_channel_binary ==1) | (sxbinary ==1)] =1\n",
    "    Frame.combined_binary = combined_binary\n",
    "'''\n",
    " #old school style\n",
    "    #stack both to see the individual contributions. Green for Sobel, Blue for Saturation (HLS)\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    Frame.color_binary = color_binary\n",
    "\n",
    "    #combine the two thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary ==1) | (sxbinary ==1)] =1\n",
    "    Frame.combined_binary = combined_binary\n",
    "'''\n",
    "#Training for lines\n",
    "def slidingWindow(Frame):\n",
    "    '''\n",
    "    Takes in a thresholded image and creates sliding windows\n",
    "    These midpoints will be used to determine the polynomial curve of the line\n",
    "    '''\n",
    "    leftLine = Frame.leftLine\n",
    "    rightLine = Frame.rightLine\n",
    "    \n",
    "    #Take histogram of bottom part of the image\n",
    "    binary_warp = Frame.combined_binary\n",
    "    histogram = np.sum(binary_warp[binary_warp.shape[0]//2:,:], axis = 0)\n",
    "\n",
    "    #Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warp, binary_warp, binary_warp))* 255\n",
    "\n",
    "    #Find peak of left and right halves of the  histogram\n",
    "    #These will be the starting points for the left and right lanes\n",
    "    midpoint = np.int(histogram.shape[0] /2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    #Choose number of sliding windows\n",
    "    nwindows = 9\n",
    "    #set height of windows\n",
    "    window_height = np.int(binary_warp.shape[0]/nwindows)\n",
    "    #Identify x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warp.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    #Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    #set width of the windows margin\n",
    "    margin = 100\n",
    "    #set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    #create empty list to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    #step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        #Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warp.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warp.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        #Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low, win_y_low),(win_xleft_high, win_y_high),(0,255,0), 2)\n",
    "        cv2.rectangle(out_img,(win_xright_low, win_y_low), (win_xright_high, win_y_high), (0,255,0), 2)\n",
    "        \n",
    "        #Identify nonzero pizels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        #Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        #If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    #Concatinate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    #Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    #Conversions from pixel to real world\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    #Fit a second order polynomial in pixel space\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #Fit a second order polynomial to each in real world space\n",
    "    left_fit_worldSpace = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_worldSpace = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "\n",
    "    #Visualize it\n",
    "    #Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warp.shape[0] -1, binary_warp.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    left_line_picture = drawLines(out_img, left_fit, (100,100,0))\n",
    "    both_line_picture = drawLines(left_line_picture, right_fit, (100,0,100))\n",
    "    Frame.both_lines = both_line_picture\n",
    "\n",
    "\n",
    "    #######################################\n",
    "    #   Update Left and Right lanes\n",
    "    ########################################\n",
    "    leftLine.updateLine(left_fit, left_fitx, left_fit_worldSpace, leftx, lefty)\n",
    "    rightLine.updateLine(right_fit, right_fitx, right_fit_worldSpace, rightx, righty)\n",
    "    findDistFromCenter(Frame)\n",
    "\n",
    "\n",
    "#If you already found it, much easier to find line pixels\n",
    "def ezFind(Frame):\n",
    "    '''\n",
    "    Solves for left and right fits given that you already have left and right fits\n",
    "    Skips the sliding window portion\n",
    "    '''\n",
    "    leftLine = Frame.leftLine\n",
    "    rightLine = Frame.rightLine\n",
    "    img = Frame.combined_binary\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "\n",
    "    #uses left line and right line current_fit\n",
    "    left_fit = leftLine.current_fit[-1]\n",
    "    right_fit = rightLine.current_fit[-1]\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) &\n",
    "                      (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) &\n",
    "                       (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    #Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    #Conversions from pixel to real world\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    #Fit a second order polynomial in pixel space\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #Fit a second order polynomial to each in real world space\n",
    "    left_fit_worldSpace = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_worldSpace = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    \n",
    "    #Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    #Visualize result\n",
    "    out_img = np.dstack((img, img, img))* 255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255,0,0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0,0,255]\n",
    "\n",
    "    #Generate a polygon to illustrate the search window area\n",
    "    #Recast the x and y points into usable format for cv2.fillpoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    #Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255,0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255,0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    left_line_picture = drawLines(out_img, left_fit, (100,100,0))\n",
    "    both_line_picture = drawLines(left_line_picture, right_fit, (100,0,100))\n",
    "    Frame.both_lines = both_line_picture\n",
    "\n",
    "\n",
    "    #######################################\n",
    "    #   Update Left and Right lanes\n",
    "    ########################################\n",
    "    leftLine.updateLine(left_fit, left_fitx, left_fit_worldSpace, leftx, lefty)\n",
    "    rightLine.updateLine(right_fit, right_fitx, right_fit_worldSpace, rightx, righty)\n",
    "    findDistFromCenter(Frame)\n",
    "\n",
    "    \n",
    "def findDistFromCenter(Frame):\n",
    "    leftLine = Frame.leftLine\n",
    "    rightLine = Frame.rightLine\n",
    "\n",
    "    img_height, img_width = Frame.original.shape[:2]\n",
    "    \n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    carPosition = img_width //2\n",
    "    #check for current fits, if none then do nothing\n",
    "    try:\n",
    "        l_fit = leftLine.current_fit[-1]\n",
    "        r_fit = rightLine.current_fit[-1]\n",
    "        leftLineXint = l_fit[0]*img_height**2 + l_fit[1]*img_height + l_fit[2]\n",
    "        rightLineXint = r_fit[0]*img_height**2 + r_fit[1]*img_height + r_fit[2]\n",
    "        laneCenter = (leftLineXint + rightLineXint)//2\n",
    "        center_dist = (carPosition - laneCenter) * xm_per_pix\n",
    "\n",
    "        Frame.line_base_pos = center_dist\n",
    "    except:\n",
    "        print('index out of range, skipping')\n",
    "\n",
    "\n",
    "#Filling in area on image\n",
    "def draw(Frame):\n",
    "    '''\n",
    "    draws the lines and area onto the original image\n",
    "    takes in the original image and the binary warped image\n",
    "    Also takes in the left and right polyfit array\n",
    "    '''\n",
    "    leftLine = Frame.leftLine\n",
    "    rightLine = Frame.rightLine\n",
    "    img = Frame.undst\n",
    "    warped_img = Frame.combined_binary\n",
    "    Minv = Frame.Minv\n",
    "\n",
    "    #Fix the average!!\n",
    "    left_fit = leftLine.best_fit\n",
    "    right_fit = rightLine.best_fit\n",
    "    \n",
    "    warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero,  warp_zero))\n",
    "\n",
    "    #Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    #Recast the x and y ponts into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    #Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "    #Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "    #Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    #draw text on the image\n",
    "    result = drawText(result, Frame)\n",
    "    #visualizeImage('Final image', result)\n",
    "    Frame.finalImage = result\n",
    "\n",
    "\n",
    "def drawLines(img, fit, color):\n",
    "    if fit is None:\n",
    "        return img\n",
    "    editImg = np.copy(img)\n",
    "    ploty = np.linspace(0, img.shape[0]-1,  img.shape[0])\n",
    "    plotx = fit[0]*ploty**2 + fit[1]*ploty + fit[2]\n",
    "    pts = np.array([np.transpose(np.vstack([plotx, ploty]))])\n",
    "    cv2.polylines(editImg, np.int32([pts]), isClosed = False, color = color, thickness = 5)\n",
    "    return editImg\n",
    "\n",
    "def drawText(img, Frame):\n",
    "    leftLine = Frame.leftLine\n",
    "    rightLine = Frame.rightLine\n",
    "    new_img = np.copy(img)\n",
    "    h = new_img.shape[0]\n",
    "    #writing down curve radius\n",
    "    text = 'Curve radius :' + '{:04.2f}'.format((leftLine.radius_of_curvature + rightLine.radius_of_curvature)/2) + 'm'\n",
    "    cv2.putText(new_img, text, (40,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    #writing down center of lane\n",
    "    center_dist = Frame.line_base_pos\n",
    "    if center_dist > 0:\n",
    "        direction = 'right'\n",
    "    else:\n",
    "        direction = 'left'\n",
    "\n",
    "    abs_center_dist = abs(center_dist)\n",
    "    text = '{:04.3f}'.format(abs_center_dist) + 'm ' + direction + ' of center'\n",
    "    cv2.putText(new_img, text, (40, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "def visualizeAll(Frame):\n",
    "    visualizeImage('original',Frame.original)\n",
    "    visualizeImage('undst', Frame.undst)\n",
    "    visualizeImage('gray', Frame.gray)\n",
    "    visualizeImage('warp', Frame.warp)\n",
    "    visualizeImage('color binary', Frame.color_binary)\n",
    "    visualizeImage('both lines', Frame.both_lines)\n",
    "    visualizeImage('final image', Frame.finalImage)\n",
    "    visualizeImage('h channel', Frame.h_channel)\n",
    "    visualizeImage('l channel', Frame.l_channel)\n",
    "    visualizeImage('s channel', Frame.s_channel)\n",
    "    visualizeImage('sobel', Frame.sxbinary)\n",
    "    visualizeImage('s channel binary', Frame.s_binary)\n",
    "    visualizeImage('mesh', Frame.mesh)\n",
    "\n",
    "def createMesh(Frame):\n",
    "    names = ['border', 'warp', 'gray', 'sobelx', 's_channel', 'sobelx_s_channel_binary', 'color_binary', 'both_lines', 'Final Image']\n",
    "    display = {'undst':Frame.undst, 'gray':Frame.gray, 'warp':Frame.warp,\n",
    "               'h_channel':Frame.h_channel, 'l_channel':Frame.l_channel, 's_channel':Frame.s_channel,\n",
    "               'color_binary':Frame.color_binary, 'both_lines':Frame.both_lines, 'Final Image':Frame.finalImage,\n",
    "               'sobelx':Frame.sxbinary, 'border':Frame.border, 'sobelx_s_channel_binary':Frame.sx_s_channel_binary}\n",
    "    height, width = Frame.original.shape[:2]\n",
    "    Frame.mesh = np.copy(Frame.original)\n",
    "    offset_x = 0\n",
    "    offset_y = 0\n",
    "    i = 0\n",
    "    for name in names:\n",
    "        text = name\n",
    "        img = np.copy(display[name])\n",
    "\n",
    "        #Check and convert from grayscale to BGR\n",
    "        if len(img.shape) < 3:\n",
    "            try:\n",
    "                #try to convert to grayscale\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            except:\n",
    "                img = np.dstack(( img, img, img)) * 255\n",
    "        \n",
    "        res = cv2.resize(img, (width//3, height //3), interpolation = cv2.INTER_LINEAR)\n",
    "        #put name in the bottom middle of the image, resize it and put it on the mesh image\n",
    "        cv2.putText(res,text, (res.shape[1] //2 - 50, res.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        Frame.mesh[offset_y:offset_y + res.shape[0], offset_x:offset_x + res.shape[1]] = res\n",
    "        \n",
    "        #update i and offset values\n",
    "        i += 1\n",
    "        if i % 3 == 0:\n",
    "            #next row\n",
    "            offset_x = 0\n",
    "            offset_y += height // 3\n",
    "        else:\n",
    "            offset_x += width // 3 \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Main Code\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#   Initialize global objects\n",
    "#####################################################\n",
    "\n",
    "Frame = Frame()\n",
    "\n",
    "##############################################\n",
    "#   Calibrate Camera\n",
    "##############################################\n",
    "\n",
    "#prepare object points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "#Arrays to store object points and image points from all the images\n",
    "Frame.objpoints = [] #3d points in real world space\n",
    "Frame.imgpoints = [] # 2d points in image plane\n",
    "\n",
    "#Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "#Step through the lsit and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #find corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    #If found, add object points, image points\n",
    "    if ret == True:\n",
    "        Frame.objpoints.append(objp)\n",
    "        Frame.imgpoints.append(corners)\n",
    "\n",
    "        #Draw and display the corners\n",
    "\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#   Import Test Image\n",
    "########################################################\n",
    "#Import test images or video file, make into for loop later\n",
    "\n",
    "def processImage(img):\n",
    "\n",
    "    ########################################################\n",
    "    #   Process Image\n",
    "    ########################################################\n",
    "    #   Use functions to process image to find curves\n",
    "\n",
    "    #Undistort original image\n",
    "    Frame.original = img\n",
    "    undistort(Frame)\n",
    "\n",
    "    #Change to bird's eye view\n",
    "    perspectiveTransform(Frame)\n",
    "    #Sobel and Sat thresh\n",
    "    thresholding(Frame, sobel_t_min = 20, sobel_t_max = 255, s_t_min = 200, s_t_max = 255)\n",
    "\n",
    "    #If we already have left and right lines, we can do ezFind. Otherwise, use sliding window method\n",
    "    if (False and Frame.leftLine.isLineDetected() and Frame.rightLine.isLineDetected()):\n",
    "        ezFind(Frame)\n",
    "    else:\n",
    "        #Use sliding window method if we haven't found anything in the last 5 checks\n",
    "        slidingWindow(Frame)\n",
    "        \n",
    "    draw(Frame)\n",
    "    #Needs to return an image for it to work\n",
    "    createMesh(Frame)\n",
    "    #visualizeAll(Frame)\n",
    "   \n",
    "    visualizeImage('mesh',Frame.mesh)\n",
    "\n",
    "    #Change retrun statement to Frame.mesh if you want to create a mesh video\n",
    "    #return Frame.finalImage\n",
    "    return Frame.mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testImage(filename):\n",
    "    #Run code for just one image\n",
    "    name = filename.split('/')[-1]\n",
    "    img = cv2.imread(filename)\n",
    "    processImage(img)\n",
    "    cv2.imwrite('output_images/'+name, Frame.finalImage)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_channel shape (720, 1280)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/1/x64/conda-bld/conda_1486587097465/work/opencv-3.1.0/modules/imgproc/src/color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function ipp_cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4c8a5228ea15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#testImage('test_images/straight_lines1.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtestImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/test4.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-4abe169afca3>\u001b[0m in \u001b[0;36mtestImage\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprocessImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d2a8b13d41db>\u001b[0m in \u001b[0;36mprocessImage\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mperspectiveTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#Sobel and Sat thresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mthresholding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_t_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_t_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#If we already have left and right lines, we can do ezFind. Otherwise, use sliding window method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-031706d139e2>\u001b[0m in \u001b[0;36mthresholding\u001b[0;34m(Frame, sobel_t_min, sobel_t_max, s_t_min, s_t_max)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#Sobelx the S_channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's_channel shape'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgray_s_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0msobel_x_s_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mabs_sobel_x_s_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msobel_x_s_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/1/x64/conda-bld/conda_1486587097465/work/opencv-3.1.0/modules/imgproc/src/color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function ipp_cvtColor\n"
     ]
    }
   ],
   "source": [
    "#testImage('test_images/straight_lines1.jpg')\n",
    "testImage('test_images/test4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/1/x64/conda-bld/conda_1486587097465/work/opencv-3.1.0/modules/imgproc/src/color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function ipp_cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5f8a660a3f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'video_output.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_video.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocessedClip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#processedClip.write_videofile(processedClip, audio = False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time processedClip.write_videofile(output_file, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-181>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \"\"\"\n\u001b[1;32m    693\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-138>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d2a8b13d41db>\u001b[0m in \u001b[0;36mprocessImage\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mperspectiveTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#Sobel and Sat thresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mthresholding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_t_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_t_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#If we already have left and right lines, we can do ezFind. Otherwise, use sliding window method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4cc2774dec20>\u001b[0m in \u001b[0;36mthresholding\u001b[0;34m(Frame, sobel_t_min, sobel_t_max, s_t_min, s_t_max)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#Sobelx the S_channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0msobel_x_s_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mabs_sobel_x_s_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msobel_x_s_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mscaled_sobel_s_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs_sobel_x_s_channel\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_sobel_x_s_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/1/x64/conda-bld/conda_1486587097465/work/opencv-3.1.0/modules/imgproc/src/color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function ipp_cvtColor\n"
     ]
    }
   ],
   "source": [
    "#Video\n",
    "output_file = 'video_output.mp4'\n",
    "input_file = VideoFileClip('project_video.mp4')\n",
    "processedClip = input_file.fl_image(processImage)\n",
    "#processedClip.write_videofile(processedClip, audio = False)\n",
    "%time processedClip.write_videofile(output_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
