{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBy: Sean Pan\\n10/10/2017\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################\n",
    "#   Advanced Lane Lines\n",
    "##############################################\n",
    "'''\n",
    "By: Sean Pan\n",
    "10/10/2017\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Import Statments\n",
    "##############################################\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Defining Line Class\n",
    "##############################################\n",
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Was the line detected in the last iteration?\n",
    "        ##done\n",
    "        self.detected = False\n",
    "        \n",
    "        #x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []\n",
    "\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype = 'float')\n",
    "        \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None\n",
    "\n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "\n",
    "    def isLineDetected(self):\n",
    "        return self.detected\n",
    "    \n",
    "    def updateLine(self, current_fit, current_fitx, allx, ally):\n",
    "        #updates the lines and sets the detected flag to true if we've had success in the past 5 runs, otherwise it sets it to false\n",
    "\n",
    "        #Check if we're detected first, if not, just add the line\n",
    "        if self.detected:\n",
    "            #update diffs\n",
    "            self.diffs = self.current_fit[-1] - current_fit\n",
    "\n",
    "        #if the differences are too high, abort and set detected to false\n",
    "        if current_fit is not None:\n",
    "            if ((self.diffs[0] > 0.001) or (self.diffs[1] > 1) or (self.diffs[2] > 100)):\n",
    "                #If difference is too crazy, abort and call remove line function\n",
    "                self.removeLine()\n",
    "            else:\n",
    "                self.detected = True\n",
    "            \n",
    "                #update all x and all y\n",
    "                self.allx = allx\n",
    "                self.ally = ally\n",
    "\n",
    "                #update polynomial coefficients\n",
    "                self.current_fit.append(current_fit)\n",
    "                self.recent_xfitted.append(current_fitx)\n",
    "                \n",
    "                if len(self.recent_xfitted) > 5:\n",
    "                    #pop the first one if we have over 5 recent fits. Over flow protection\n",
    "                    self.recent_xfitted.pop(0)\n",
    "                if len(self.current_fit) > 5:\n",
    "                    self.current_fit.pop(0)\n",
    "                  \n",
    "                #average lines here and set bestx and best_fit values. Use these values for drawings\n",
    "                if len(self.recent_xfitted) > 0:\n",
    "                    self.bestx = np.average(self.recent_xfitted, axis = 0)\n",
    "                if len(self.current_fit) > 0 :\n",
    "                    self.best_fit = np.average(self.current_fit, axis = 0)\n",
    "\n",
    "                #Find curvature\n",
    "                self.findRadius()\n",
    "        #Else, no line available, set flag to not detected\n",
    "        else:\n",
    "            self.removeLine()\n",
    "\n",
    "\n",
    "\n",
    "    def removeLine(self):\n",
    "        #remove oldest instance of recent_xfitted and current_fit so that when it's 0 we can do sliding window method again\n",
    "        if len(self.recent_xfitted) > 0:\n",
    "            self.recent_xfitted.pop(0)\n",
    "        if len(self.current_fit) > 0:\n",
    "            self.current_fit.pop(0)\n",
    "        if len(self.recent_xfitted) == 0 or len(self.current_fit) ==0:\n",
    "            #When we have nothing left, reset and go back to default values\n",
    "            self.detected = False\n",
    "            self.diffs = np.array([0,0,0], dtype = 'float')\n",
    "     \n",
    "    def findRadius(self, height = 720):\n",
    "        #Second argument is either 720 or image size\n",
    "        \n",
    "        #Conversions from pixel to real world\n",
    "        ploty = np.linspace(0, height -1, height)\n",
    "        y_eval = np.max(ploty)\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        \n",
    "        fit_worldSpace = np.polyfit(ym_per_pix * self.ally, xm_per_pix * self.allx, 2)\n",
    "\n",
    "        curverad = ((1 + (2*fit_worldSpace[0] * y_eval * ym_per_pix+ fit_worldSpace[1])**2)**1.5)/ np.absolute(2*fit_worldSpace[0])\n",
    "        self.radius_of_curvature = curverad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Defining Functions\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistort(img, objpoints, imgpoints):\n",
    "    '''\n",
    "    undistorts and image\n",
    "    input: image, list of objpoints, and list of imgpoints\n",
    "    output: undistorted image\n",
    "    '''\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #print(img_size)\n",
    "\n",
    "    #Do camera calibration give obj points and img points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    undst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    return undst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualizeUndistort(img, undst):\n",
    "    \n",
    "    cv2.imshow('img', img)\n",
    "    cv2.imshow('undst', undst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeImage(name, img):\n",
    "    #pass\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(50)\n",
    "    #convert from bgr to rgb\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(img)\n",
    "    #plt.title(name)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transform to birds eye view\n",
    "def perspectiveTransform(undst):\n",
    "    '''\n",
    "    updates a photo to make it bird's eye view\n",
    "    input: Original image\n",
    "    output: Transformed image\n",
    "    '''\n",
    "    offset = 50\n",
    "    img_size = (undst.shape[1], undst.shape[0])\n",
    "\n",
    "    #find source and destination points\n",
    "    #####################################################\n",
    "    #src = np.float32([[630, 425], [650,425], [1060, 670], [250, 670]]) # find points from my mask?\n",
    "    #630, 425 650, 425 250, 670, 1060, 670\n",
    "    #src = np.float32([[575, 465], [710,465], [250, 670], [1050, 670]])\n",
    "    src = np.float32([[540, 465], [740,465], [95, 670], [1185, 670]])\n",
    "    #####################################################\n",
    "    dst = np.float32([[offset, offset], [img_size[0] - offset, offset], [offset, img_size[1] - offset], [img_size[0] - offset, img_size[1] - offset]])\n",
    "    #dst = np.float32([[offset, 0], [img_size[0] - offset , 0], [offset, img_size[1]], [img_size[0] - offset, img_size[1]]]) \n",
    "    #compute perspective transform, M\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    #warp image\n",
    "    warp = cv2.warpPerspective(undst, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return (warp, Minv)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sobel x plus S_gradient, put on mask\n",
    "def thresholding(img, sobel_t_min = 50, sobel_t_max = 255, s_t_min = 200, s_t_max = 255):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #visualizeImage('gray', gray)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) \n",
    "    abs_sobelx = np.absolute(sobelx)   \n",
    "    scaled_sobel = abs_sobelx    # This doesn't work np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "   \n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sobel_t_min) & (scaled_sobel <= sobel_t_max)] = 1\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    ##Debugging\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    visualizeImage('hls', hls)\n",
    "    visualizeImage('h_channel', h_channel)\n",
    "    visualizeImage('l_channel', l_channel)\n",
    "    visualizeImage('s_channel', s_channel)\n",
    "\n",
    "    #S binary\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_t_min) & (s_channel <= s_t_max)] = 1\n",
    "    #print('s_binary', s_binary)\n",
    "    visualizeImage('s_binary', s_binary)\n",
    "\n",
    "    #L binary\n",
    "    #l_binary = np.zeros_like(l_channel)\n",
    "    #l_binary[(l_channel >= s_t_min) & (l_channel <= s_t_max)] = 1\n",
    "    #visualizeImage('l_channel', l_binary)\n",
    "\n",
    "    #stack both to see the individual contributions. Green for Sobel, Blue for Saturation (HLS)\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "\n",
    "    #color_binary = np.dstack((np.zeros_like(sxbinary), sxbinary, l_binary))*255\n",
    "    #combine the two thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary ==1) | (sxbinary ==1)] =1\n",
    "    visualizeImage('color_binary', color_binary)\n",
    "\n",
    "    return combined_binary\n",
    "\n",
    "#Training for lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindow(binary_warp, leftLine, rightLine):\n",
    "    '''\n",
    "    Takes in a thresholded image and creates sliding windows\n",
    "    These midpoints will be used to determine the polynomial curve of the line\n",
    "    '''\n",
    "    #Take histogram of bottom part of the image\n",
    "    histogram = np.sum(binary_warp[binary_warp.shape[0]//2:,:], axis = 0)\n",
    "\n",
    "    #Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warp, binary_warp, binary_warp))* 255\n",
    "\n",
    "    #Find peak of left and right halves of the  histogram\n",
    "    #These will be the starting points for the left and right lanes\n",
    "    midpoint = np.int(histogram.shape[0] /2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    #Choose number of sliding windows\n",
    "    nwindows = 9\n",
    "    #set height of windows\n",
    "    window_height = np.int(binary_warp.shape[0]/nwindows)\n",
    "    #Identify x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warp.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    #Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    #set width of the windows margin\n",
    "    margin = 100\n",
    "    #set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    #create empty list to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    #step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        #Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warp.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warp.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        #Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low, win_y_low),(win_xleft_high, win_y_high),(0,255,0), 2)\n",
    "        cv2.rectangle(out_img,(win_xright_low, win_y_low), (win_xright_high, win_y_high), (0,255,0), 2)\n",
    "        #Identify nonzero pizels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        #Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        #If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    #Concatinate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    #Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    #Conversions from pixel to real world\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    #Fit a second order polynomial in pixel space\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #Fit a second order polynomial to each in real world space\n",
    "    left_fit_worldSpace = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_worldSpace = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "\n",
    "    #Visualize it\n",
    "    #Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warp.shape[0] -1, binary_warp.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    plt.imshow(out_img)\n",
    "\n",
    "    #visualizeImage('out_img', out_img)\n",
    "    plt.plot(left_fitx, ploty, color = 'yellow')\n",
    "    plt.plot(right_fitx, ploty, color = 'yellow')\n",
    "    plt.xlim(0, 1289)\n",
    "    plt.ylim(720, 0)\n",
    "\n",
    "    left_line_picture = drawLines(out_img, left_fit, (100,100,0))\n",
    "    both_line_picture = drawLines(left_line_picture, right_fit, (100,0,100))\n",
    "    visualizeImage('both lines', both_line_picture)\n",
    "    \n",
    "    \n",
    "\n",
    "    #######################################\n",
    "    #   Update Left and Right lanes\n",
    "    ########################################\n",
    "    leftLine.updateLine(left_fit, left_fitx, leftx, lefty)\n",
    "    rightLine.updateLine(right_fit, right_fitx, rightx, righty)\n",
    "    findDistFromCenter(leftLine, rightLine, img_width = 1280, img_height = 720)\n",
    "    \n",
    "    return (left_fit, right_fit, left_fit_worldSpace, right_fit_worldSpace) #Return numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If you already found it, much easier to find line pixels\n",
    "def ezFind(img, leftLine, rightLine):\n",
    "    '''\n",
    "    Solves for left and right fits given that you already have left and right fits\n",
    "    Skips the sliding window portion\n",
    "    '''\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "\n",
    "    #uses left line and right line current_fit\n",
    "    left_fit = leftLine.current_fit[-1]\n",
    "    right_fit = rightLine.current_fit[-1]\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) &\n",
    "                      (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) &\n",
    "                       (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    #Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    #Fit a second order polynomial in pixel space\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    #Visualize result\n",
    "    out_img = np.dstack((img, img, img))* 255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255,0,0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0,0,255]\n",
    "    visualizeImage('out_img', out_img)\n",
    "    #Generate a polygon to illustrate the search window area\n",
    "    #Recast the x and y points into usable format for cv2.fillpoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    #Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255,0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255,0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    #plt.imshow(result)\n",
    "    #plt.plot(left_fitx, ploty, color = 'yellow')\n",
    "    #plt.plot(right_fitx, ploty, color = 'yellow')\n",
    "    #plt.xlim(0, 1280)\n",
    "    #plt.ylim(720, 0)\n",
    "\n",
    "    \n",
    "    #######################################\n",
    "    #   Update Left and Right lanes\n",
    "    ########################################\n",
    "    leftLine.updateLine(left_fit, left_fitx, leftx, lefty)\n",
    "    rightLine.updateLine(right_fit, right_fitx, rightx, righty)\n",
    "    findDistFromCenter(leftLine, rightLine, img_width = 1280, img_height = 720)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findDistFromCenter(leftLine, rightLine, img_width = 1280, img_height = 720):\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    carPosition = img_width //2\n",
    "    l_fit = leftLine.current_fit[-1]\n",
    "    r_fit = rightLine.current_fit[-1]\n",
    "    leftLineXint = l_fit[0]*img_height**2 + l_fit[1]*img_height + l_fit[2]\n",
    "    rightLineXint = r_fit[0]*img_height**2 + r_fit[1]*img_height + r_fit[2]\n",
    "    laneCenter = (leftLineXint + rightLineXint)//2\n",
    "    center_dist = (carPosition - laneCenter) * xm_per_pix\n",
    "    leftLine.line_base_pos = center_dist #repeat for redundancy\n",
    "    rightLine.line_base_pos = center_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filling in area on image\n",
    "def draw(img, warped_img, Minv, leftLine, rightLine):\n",
    "    '''\n",
    "    draws the lines and area onto the original image\n",
    "    takes in the original image and the binary warped image\n",
    "    Also takes in the left and right polyfit array\n",
    "    '''\n",
    "\n",
    "    #Fix the average!!\n",
    "    left_fit = leftLine.best_fit\n",
    "    right_fit = rightLine.best_fit\n",
    "    \n",
    "    warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero,  warp_zero))\n",
    "\n",
    "    #Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    #Recast the x and y ponts into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    #Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "    #visualizeImage('before warp', color_warp)\n",
    "    #Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "    #Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    #plt.imshow(result)\n",
    "\n",
    "    #draw text on the image\n",
    "    result = drawText(result, leftLine, rightLine)\n",
    "    visualizeImage('Final image', result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawLines(img, fit, color):\n",
    "    if fit is None:\n",
    "        return img\n",
    "    editImg = np.copy(img)\n",
    "    ploty = np.linspace(0, img.shape[0]-1,  img.shape[0])\n",
    "    plotx = fit[0]*ploty**2 + fit[1]*ploty + fit[2]\n",
    "    pts = np.array([np.transpose(np.vstack([plotx, ploty]))])\n",
    "    cv2.polylines(editImg, np.int32([pts]), isClosed = False, color = color, thickness = 5)\n",
    "    return editImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawText(img, leftLine, rightLine):\n",
    "    new_img = np.copy(img)\n",
    "    h = new_img.shape[0]\n",
    "    #writing down curve radius\n",
    "    text = 'Curve radius :' + '{:04.2f}'.format((leftLine.radius_of_curvature + rightLine.radius_of_curvature)/2) + 'm'\n",
    "    cv2.putText(new_img, text, (40,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    #writing down center of lane\n",
    "    center_dist = leftLine.line_base_pos\n",
    "    if center_dist > 0:\n",
    "        direction = 'right'\n",
    "    else:\n",
    "        direction = 'left'\n",
    "\n",
    "    abs_center_dist = abs(center_dist)\n",
    "    text = '{:04.3f}'.format(abs_center_dist) + 'm ' + direction + ' of center'\n",
    "    cv2.putText(new_img, text, (40, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#   Main Code\n",
    "##############################################\n",
    "\n",
    "##############################################\n",
    "#   Calibrate Camera\n",
    "##############################################\n",
    "\n",
    "#prepare object points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "#Arrays to store object points and image points from all the images\n",
    "objpoints = [] #3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "#Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "#Step through the lsit and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #find corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    #If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        #Draw and display the corners\n",
    "        #matplot lib this\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#   Create Lines\n",
    "#####################################################\n",
    "leftLine = Line()\n",
    "rightLine = Line()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "#   Import Test Image\n",
    "########################################################\n",
    "#Import test images or video file, make into for loop later\n",
    "\n",
    "def processImage(img):\n",
    "\n",
    "    #img = cv2.imread('test_images/straight_lines1.jpg')\n",
    "\n",
    "    ########################################################\n",
    "    #   Process Image\n",
    "    ########################################################\n",
    "    #   Use functions to process image to find curves\n",
    "\n",
    "    #Undistort original image\n",
    "    #name = filename.split('/')[-1]\n",
    "    #img = cv2.imread(filename)\n",
    "    undst = undistort(img, objpoints, imgpoints)\n",
    "\n",
    "    #Change to bird's eye view\n",
    "    warp, Minv = perspectiveTransform(undst)\n",
    "    visualizeImage('warp',warp)\n",
    "    #Sobel and Sat thresh\n",
    "    binary_warp = thresholding(warp, sobel_t_min = 40, sobel_t_max = 255, s_t_min = 200, s_t_max = 255)\n",
    "    visualizeImage('binary_warp',binary_warp)\n",
    "\n",
    "    #If we already have left and right lines, we can do ezFind. Otherwise, use sliding window method\n",
    "    if (leftLine.isLineDetected() and rightLine.isLineDetected()):\n",
    "        ezFind(binary_warp, leftLine, rightLine)\n",
    "    else:\n",
    "        #Use sliding window method if we haven't found anything in the last 5 checks\n",
    "        slidingWindow(binary_warp, leftLine, rightLine)\n",
    "        \n",
    "    finalImage = draw(undst, binary_warp, Minv, leftLine, rightLine)\n",
    "    return finalImage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testImage(filename):\n",
    "    #Run code for just one image\n",
    "    name = filename.split('/')[-1]\n",
    "    img = cv2.imread(filename)\n",
    "    finalImage = processImage(img)\n",
    "    cv2.imwrite('output_images/'+name, finalImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage('test_images/test1.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video video_output.mp4\n",
      "[MoviePy] Writing video video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/126 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/126 [00:01<03:54,  1.88s/it]\u001b[A\n",
      "  2%|▏         | 2/126 [00:03<03:53,  1.88s/it]\u001b[A\n",
      "  2%|▏         | 3/126 [00:05<03:51,  1.88s/it]\u001b[A\n",
      "  3%|▎         | 4/126 [00:07<03:47,  1.87s/it]\u001b[A\n",
      "  4%|▍         | 5/126 [00:09<03:46,  1.87s/it]\u001b[A\n",
      "  5%|▍         | 6/126 [00:11<03:46,  1.89s/it]\u001b[A\n",
      "  6%|▌         | 7/126 [00:13<03:50,  1.94s/it]\u001b[A\n",
      "  6%|▋         | 8/126 [00:15<03:47,  1.92s/it]\u001b[A\n",
      "  7%|▋         | 9/126 [00:17<03:43,  1.91s/it]\u001b[A\n",
      "  8%|▊         | 10/126 [00:19<03:43,  1.92s/it]\u001b[A\n",
      "  9%|▊         | 11/126 [00:20<03:40,  1.92s/it]\u001b[A\n",
      " 10%|▉         | 12/126 [00:23<03:45,  1.98s/it]\u001b[A\n",
      " 10%|█         | 13/126 [00:25<03:47,  2.02s/it]\u001b[A\n",
      " 11%|█         | 14/126 [00:27<03:46,  2.03s/it]\u001b[A\n",
      " 12%|█▏        | 15/126 [00:29<03:44,  2.03s/it]\u001b[A\n",
      " 13%|█▎        | 16/126 [00:31<03:40,  2.00s/it]\u001b[A\n",
      " 13%|█▎        | 17/126 [00:33<03:36,  1.98s/it]\u001b[A\n",
      " 14%|█▍        | 18/126 [00:35<03:32,  1.96s/it]\u001b[A\n",
      " 15%|█▌        | 19/126 [00:36<03:27,  1.94s/it]\u001b[A\n",
      " 16%|█▌        | 20/126 [00:38<03:23,  1.92s/it]\u001b[A\n",
      " 17%|█▋        | 21/126 [00:40<03:19,  1.90s/it]\u001b[A\n",
      " 17%|█▋        | 22/126 [00:42<03:16,  1.89s/it]\u001b[A\n",
      " 18%|█▊        | 23/126 [00:44<03:14,  1.88s/it]\u001b[A\n",
      " 19%|█▉        | 24/126 [00:46<03:12,  1.88s/it]\u001b[A\n",
      " 20%|█▉        | 25/126 [00:48<03:11,  1.90s/it]\u001b[A\n",
      " 21%|██        | 26/126 [00:50<03:09,  1.90s/it]\u001b[A\n",
      " 21%|██▏       | 27/126 [00:52<03:08,  1.90s/it]\u001b[A\n",
      " 22%|██▏       | 28/126 [00:53<03:06,  1.90s/it]\u001b[A\n",
      " 23%|██▎       | 29/126 [00:55<03:05,  1.91s/it]\u001b[A\n",
      " 24%|██▍       | 30/126 [00:57<03:03,  1.92s/it]\u001b[A\n",
      " 25%|██▍       | 31/126 [00:59<03:07,  1.98s/it]\u001b[A\n",
      " 25%|██▌       | 32/126 [01:01<03:08,  2.01s/it]\u001b[A\n",
      " 26%|██▌       | 33/126 [01:03<03:04,  1.98s/it]\u001b[A\n",
      " 27%|██▋       | 34/126 [01:05<03:00,  1.96s/it]\u001b[A\n",
      " 28%|██▊       | 35/126 [01:07<02:56,  1.94s/it]\u001b[A\n",
      " 29%|██▊       | 36/126 [01:09<02:52,  1.92s/it]\u001b[A\n",
      " 29%|██▉       | 37/126 [01:11<02:52,  1.94s/it]\u001b[A\n",
      " 30%|███       | 38/126 [01:13<02:51,  1.94s/it]\u001b[A\n",
      " 31%|███       | 39/126 [01:15<02:47,  1.92s/it]\u001b[A\n",
      " 32%|███▏      | 40/126 [01:17<02:43,  1.91s/it]\u001b[A\n",
      " 33%|███▎      | 41/126 [01:19<02:41,  1.90s/it]\u001b[A\n",
      " 33%|███▎      | 42/126 [01:21<02:38,  1.89s/it]\u001b[A\n",
      " 34%|███▍      | 43/126 [01:22<02:37,  1.90s/it]\u001b[A\n",
      " 35%|███▍      | 44/126 [01:24<02:36,  1.90s/it]\u001b[A\n",
      " 36%|███▌      | 45/126 [01:26<02:33,  1.90s/it]\u001b[A\n",
      " 37%|███▋      | 46/126 [01:28<02:31,  1.89s/it]\u001b[A\n",
      " 37%|███▋      | 47/126 [01:30<02:29,  1.89s/it]\u001b[A\n",
      " 38%|███▊      | 48/126 [01:32<02:27,  1.89s/it]\u001b[A\n",
      " 39%|███▉      | 49/126 [01:34<02:25,  1.89s/it]\u001b[A\n",
      " 40%|███▉      | 50/126 [01:36<02:22,  1.88s/it]\u001b[A\n",
      " 40%|████      | 51/126 [01:38<02:21,  1.88s/it]\u001b[A\n",
      " 41%|████▏     | 52/126 [01:39<02:18,  1.88s/it]\u001b[A\n",
      " 42%|████▏     | 53/126 [01:41<02:16,  1.87s/it]\u001b[A\n",
      " 43%|████▎     | 54/126 [01:43<02:14,  1.87s/it]\u001b[A\n",
      " 44%|████▎     | 55/126 [01:45<02:12,  1.87s/it]\u001b[A\n",
      " 44%|████▍     | 56/126 [01:47<02:12,  1.89s/it]\u001b[A\n",
      " 45%|████▌     | 57/126 [01:49<02:11,  1.90s/it]\u001b[A\n",
      " 46%|████▌     | 58/126 [01:51<02:08,  1.89s/it]\u001b[A\n",
      " 47%|████▋     | 59/126 [01:53<02:05,  1.88s/it]\u001b[A\n",
      " 48%|████▊     | 60/126 [01:54<02:03,  1.86s/it]\u001b[A\n",
      " 48%|████▊     | 61/126 [01:56<02:00,  1.86s/it]\u001b[A\n",
      " 49%|████▉     | 62/126 [01:58<01:58,  1.85s/it]\u001b[A\n",
      " 50%|█████     | 63/126 [02:00<01:56,  1.84s/it]\u001b[A\n",
      " 51%|█████     | 64/126 [02:02<01:54,  1.84s/it]\u001b[A\n",
      " 52%|█████▏    | 65/126 [02:04<01:52,  1.84s/it]\u001b[A\n",
      " 52%|█████▏    | 66/126 [02:05<01:50,  1.84s/it]\u001b[A\n",
      " 53%|█████▎    | 67/126 [02:07<01:49,  1.85s/it]\u001b[A\n",
      " 54%|█████▍    | 68/126 [02:09<01:47,  1.85s/it]\u001b[A\n",
      " 55%|█████▍    | 69/126 [02:11<01:45,  1.84s/it]\u001b[A\n",
      " 56%|█████▌    | 70/126 [02:13<01:42,  1.84s/it]\u001b[A\n",
      " 56%|█████▋    | 71/126 [02:15<01:41,  1.84s/it]\u001b[A\n",
      " 57%|█████▋    | 72/126 [02:16<01:39,  1.85s/it]\u001b[A\n",
      " 58%|█████▊    | 73/126 [02:18<01:37,  1.85s/it]\u001b[A\n",
      " 59%|█████▊    | 74/126 [02:20<01:35,  1.84s/it]\u001b[A\n",
      " 60%|█████▉    | 75/126 [02:22<01:33,  1.84s/it]\u001b[A\n",
      " 60%|██████    | 76/126 [02:24<01:31,  1.83s/it]\u001b[A\n",
      " 61%|██████    | 77/126 [02:26<01:29,  1.83s/it]\u001b[A\n",
      " 62%|██████▏   | 78/126 [02:28<01:28,  1.85s/it]\u001b[A\n",
      " 63%|██████▎   | 79/126 [02:29<01:27,  1.86s/it]\u001b[A\n",
      " 63%|██████▎   | 80/126 [02:31<01:25,  1.86s/it]\u001b[A\n",
      " 64%|██████▍   | 81/126 [02:33<01:24,  1.87s/it]\u001b[A\n",
      " 65%|██████▌   | 82/126 [02:35<01:21,  1.86s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-175>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-174>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-173>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    347\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                            \u001b[0mffmpeg_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mffmpeg_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                            progress_bar=progress_bar)\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     for t,frame in clip.iter_frames(progress_bar=progress_bar, with_times=True,\n\u001b[0;32m--> 209\u001b[0;31m                                     fps=fps, dtype=\"uint8\"):\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                 \u001b[0;31m# Update and print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-138>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-c4b645476e5e>\u001b[0m in \u001b[0;36mprocessImage\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#If we already have left and right lines, we can do ezFind. Otherwise, use sliding window method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleftLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misLineDetected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrightLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misLineDetected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mezFind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_warp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightLine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#Use sliding window method if we haven't found anything in the last 5 checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-0bf3294edc6e>\u001b[0m in \u001b[0;36mezFind\u001b[0;34m(img, leftLine, rightLine)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mleftLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mrightLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mfindDistFromCenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-723fe53a748a>\u001b[0m in \u001b[0;36mfindDistFromCenter\u001b[0;34m(leftLine, rightLine, img_width, img_height)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcarPosition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ml_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleftLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mr_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrightLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mleftLineXint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_height\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrightLineXint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_height\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "output_file = 'video_output.mp4'\n",
    "input_file = VideoFileClip('project_video.mp4').subclip(20,25)\n",
    "processedClip = input_file.fl_image(processImage)\n",
    "#processedClip.write_videofile(processedClip, audio = False)\n",
    "%time processedClip.write_videofile(output_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
